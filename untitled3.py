# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13aDenz2TxyxajhtGL8gdvU3ninhfI6UC
"""

import pandas as pd
from itertools import combinations

# a) Read the CSV file into a pandas DataFrame
# Assuming the file has no header and is space-separated
df = pd.read_csv("http://fimi.uantwerpen.be/data/chess.dat", header=None, sep=" ")

# b) Transform the DataFrame into a list of transactions
transactions = df.apply(lambda row: set(row.dropna().astype(str)), axis=1).tolist()

# c) Generate all association rules with length 2, support at least 0.01, confidence at least 2, and lift at least 3
min_support = 0.01
min_confidence = 2
min_lift = 3
rules = []
itemsets = set.union(*transactions)

for item1, item2 in combinations(itemsets, 2):
    support_item1 = sum(1 for transaction in transactions if item1 in transaction) / len(transactions)
    support_item2 = sum(1 for transaction in transactions if item2 in transaction) / len(transactions)
    support_itemset = sum(1 for transaction in transactions if {item1, item2}.issubset(transaction)) / len(transactions)

    print(f"Support for {item1}: {support_item1}")
    print(f"Support for {item2}: {support_item2}")
    print(f"Support for {item1} and {item2}: {support_itemset}")

    if support_itemset >= min_support:
        confidence_item1_to_item2 = support_itemset / support_item1
        confidence_item2_to_item1 = support_itemset / support_item2
        lift_item1_to_item2 = confidence_item1_to_item2 / support_item2
        lift_item2_to_item1 = confidence_item2_to_item1 / support_item1

        print(f"Confidence from {item1} to {item2}: {confidence_item1_to_item2}")
        print(f"Confidence from {item2} to {item1}: {confidence_item2_to_item1}")
        print(f"Lift from {item1} to {item2}: {lift_item1_to_item2}")
        print(f"Lift from {item2} to {item1}: {lift_item2_to_item1}")

        if (confidence_item1_to_item2 >= min_confidence and lift_item1_to_item2 >= min_lift):
            print(f"Rule added: {item1} -> {item2}")
            rules.append((item1, item2, support_itemset, confidence_item1_to_item2, lift_item1_to_item2))
        if (confidence_item2_to_item1 >= min_confidence and lift_item2_to_item1 >= min_lift):
            print(f"Rule added: {item2} -> {item1}")
            rules.append((item2, item1, support_itemset, confidence_item2_to_item1, lift_item2_to_item1))

# d) Print out the rules in a readable form
for rule in rules:
    antecedent = rule[0]
    consequent = rule[1]
    support = round(rule[2], 4)
    confidence = round(rule[3], 4)
    lift = round(rule[4], 4)
    print(f"Rule: {antecedent} -> {consequent} | Support: {support}, Confidence: {confidence}, Lift: {lift}")

# Print the number of rules found
print(f"Number of rules: {len(rules)}")

import pandas as pd
from itertools import combinations

# a) Read the CSV file into a pandas DataFrame
# Assuming the file has no header and is space-separated
df = pd.read_csv("http://fimi.uantwerpen.be/data/chess.dat", header=None, sep=" ")

# b) Transform the DataFrame into a list of transactions
transactions = df.apply(lambda row: set(row.dropna().astype(str)), axis=1).tolist()

# c) Generate all association rules with length 2, support at least 0.01
min_support = 0.01
rules = []
itemsets = set.union(*transactions)

for item1, item2 in combinations(itemsets, 2):
    support_item1 = sum(1 for transaction in transactions if item1 in transaction) / len(transactions)
    support_item2 = sum(1 for transaction in transactions if item2 in transaction) / len(transactions)
    support_itemset = sum(1 for transaction in transactions if {item1, item2}.issubset(transaction)) / len(transactions)

    print(f"Support for {item1}: {support_item1}")
    print(f"Support for {item2}: {support_item2}")
    print(f"Support for {item1} and {item2}: {support_itemset}")

    if support_itemset >= min_support:
        print(f"Rule added: {item1} -> {item2}")
        rules.append((item1, item2, support_itemset))

# d) Print out the rules in a readable form
for rule in rules:
    antecedent = rule[0]
    consequent = rule[1]
    support = round(rule[2], 4)
    print(f"Rule: {antecedent} -> {consequent} | Support: {support}")

# Print the number of rules found
print(f"Number of rules: {len(rules)}")

import pandas as pd
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# a) Read the CSV file into a pandas DataFrame
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv"
df = pd.read_csv(url)

# b) Extract the 12 numerical attributes
numerical_attributes = df.select_dtypes(include=['number']).iloc[:, :12]

# c) Apply PCA to find the two main components
pca = PCA(n_components=2)
principal_components = pca.fit_transform(numerical_attributes)

# d) Plot the two components using a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(principal_components[:, 0], principal_components[:, 1])
plt.title('PCA of 12 Numerical Attributes')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.grid(True)
plt.show()

# e) Find the total explained variance ratio of the two components
total_explained_variance_ratio = sum(pca.explained_variance_ratio_)
print("Total Explained Variance Ratio:", total_explained_variance_ratio)